% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\title{An R Markdown document converted from
C:/Users/Octopus/Documents/R/ensembling-different-classification-models.ipynb}
\author{}
\date{\vspace{-2.5em}}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={An R Markdown document converted from C:/Users/Octopus/Documents/R/ensembling-different-classification-models.ipynb},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}
\maketitle

\hypertarget{trying-out-and-ensembling-different-classification-models}{%
\section{Trying Out and Ensembling Different Classification
Models}\label{trying-out-and-ensembling-different-classification-models}}

\hypertarget{importing-libraries}{%
\section{Importing Libraries}\label{importing-libraries}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --
\end{verbatim}

\begin{verbatim}
## v ggplot2 3.3.5     v purrr   0.3.4
## v tibble  3.1.2     v dplyr   1.0.7
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1
\end{verbatim}

\begin{verbatim}
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidymodels)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Registered S3 method overwritten by 'tune':
##   method                   from   
##   required_pkgs.model_spec parsnip
\end{verbatim}

\begin{verbatim}
## -- Attaching packages -------------------------------------- tidymodels 0.1.3 --
\end{verbatim}

\begin{verbatim}
## v broom        0.7.10     v rsample      0.1.0 
## v dials        0.0.10     v tune         0.1.6 
## v infer        0.5.4      v workflows    0.2.3 
## v modeldata    0.1.1      v workflowsets 0.1.0 
## v parsnip      0.1.7      v yardstick    0.0.8 
## v recipes      0.1.16
\end{verbatim}

\begin{verbatim}
## -- Conflicts ----------------------------------------- tidymodels_conflicts() --
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()
## * Use tidymodels_prefer() to resolve common conflicts.
\end{verbatim}

\hypertarget{dataset}{%
\section{Dataset}\label{dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mine }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"C:/Users/Octopus/Desktop/in{-}vehicle{-}coupon{-}recommendation.csv"}\NormalTok{, }\AttributeTok{stringsAsFactors=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{head}\NormalTok{(mine)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       destination passanger weather temperature time                coupon
## 1 No Urgent Place     Alone   Sunny          55  2PM       Restaurant(<20)
## 2 No Urgent Place Friend(s)   Sunny          80 10AM          Coffee House
## 3 No Urgent Place Friend(s)   Sunny          80 10AM Carry out & Take away
## 4 No Urgent Place Friend(s)   Sunny          80  2PM          Coffee House
## 5 No Urgent Place Friend(s)   Sunny          80  2PM          Coffee House
## 6 No Urgent Place Friend(s)   Sunny          80  6PM       Restaurant(<20)
##   expiration gender age     maritalStatus has_children                education
## 1         1d Female  21 Unmarried partner            1 Some college - no degree
## 2         2h Female  21 Unmarried partner            1 Some college - no degree
## 3         2h Female  21 Unmarried partner            1 Some college - no degree
## 4         2h Female  21 Unmarried partner            1 Some college - no degree
## 5         1d Female  21 Unmarried partner            1 Some college - no degree
## 6         2h Female  21 Unmarried partner            1 Some college - no degree
##   occupation          income   Bar CoffeeHouse RestaurantLessThan20
## 1 Unemployed $37500 - $49999 never       never                  4~8
## 2 Unemployed $37500 - $49999 never       never                  4~8
## 3 Unemployed $37500 - $49999 never       never                  4~8
## 4 Unemployed $37500 - $49999 never       never                  4~8
## 5 Unemployed $37500 - $49999 never       never                  4~8
## 6 Unemployed $37500 - $49999 never       never                  4~8
##   Restaurant20To50 toCoupon_GEQ15min toCoupon_GEQ25min direction_same
## 1              1~3                 0                 0              0
## 2              1~3                 0                 0              0
## 3              1~3                 1                 0              0
## 4              1~3                 1                 0              0
## 5              1~3                 1                 0              0
## 6              1~3                 1                 0              0
##   direction_opp Y
## 1             1 1
## 2             1 0
## 3             1 1
## 4             1 0
## 5             1 0
## 6             1 1
\end{verbatim}

Let's have a glimpse of what our dataset looks like.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{skimmed }\OtherTok{\textless{}{-}}\NormalTok{ skimr}\SpecialCharTok{::}\FunctionTok{skim}\NormalTok{(mine)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in sorted_count(x): Variable contains value(s) of "" that have been
## converted to "empty".

## Warning in sorted_count(x): Variable contains value(s) of "" that have been
## converted to "empty".

## Warning in sorted_count(x): Variable contains value(s) of "" that have been
## converted to "empty".

## Warning in sorted_count(x): Variable contains value(s) of "" that have been
## converted to "empty".
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{skimmed }\OtherTok{\textless{}{-}}\NormalTok{ skimmed[, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{9}\SpecialCharTok{:}\DecValTok{11}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{)]}
\NormalTok{skimmed}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ll@{}}
\caption{Data summary}\tabularnewline
\toprule
\endhead
Name & mine \\
Number of rows & 12684 \\
Number of columns & 23 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Column type frequency: & \\
factor & 16 \\
numeric & 7 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Group variables & None \\
\bottomrule
\end{longtable}

\textbf{Variable type: factor}

\begin{longtable}[]{@{}lrrl@{}}
\toprule
skim\_variable & n\_missing & complete\_rate & ordered \\
\midrule
\endhead
destination & 0 & 1 & FALSE \\
passanger & 0 & 1 & FALSE \\
weather & 0 & 1 & FALSE \\
time & 0 & 1 & FALSE \\
coupon & 0 & 1 & FALSE \\
expiration & 0 & 1 & FALSE \\
gender & 0 & 1 & FALSE \\
age & 0 & 1 & FALSE \\
maritalStatus & 0 & 1 & FALSE \\
education & 0 & 1 & FALSE \\
occupation & 0 & 1 & FALSE \\
income & 0 & 1 & FALSE \\
Bar & 0 & 1 & FALSE \\
CoffeeHouse & 0 & 1 & FALSE \\
RestaurantLessThan20 & 0 & 1 & FALSE \\
Restaurant20To50 & 0 & 1 & FALSE \\
\bottomrule
\end{longtable}

\textbf{Variable type: numeric}

\begin{longtable}[]{@{}lrrrrrrl@{}}
\toprule
skim\_variable & n\_missing & complete\_rate & sd & p0 & p25 & p75 &
hist \\
\midrule
\endhead
temperature & 0 & 1 & 19.15 & 30 & 55 & 80 & ▃▁▅▁▇ \\
has\_children & 0 & 1 & 0.49 & 0 & 0 & 1 & ▇▁▁▁▆ \\
toCoupon\_GEQ15min & 0 & 1 & 0.50 & 0 & 0 & 1 & ▆▁▁▁▇ \\
toCoupon\_GEQ25min & 0 & 1 & 0.32 & 0 & 0 & 0 & ▇▁▁▁▁ \\
direction\_same & 0 & 1 & 0.41 & 0 & 0 & 0 & ▇▁▁▁▂ \\
direction\_opp & 0 & 1 & 0.41 & 0 & 1 & 1 & ▂▁▁▁▇ \\
Y & 0 & 1 & 0.50 & 0 & 0 & 1 & ▆▁▁▁▇ \\
\bottomrule
\end{longtable}

The response variable, Y appears to be numeric. It should be a factor,
so we should convert it with factor(). Also, it seems that the
temperature column has only three numbers, so we should also treat it as
a factor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mine }\OtherTok{\textless{}{-}}\NormalTok{ mine }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{temperature =} \FunctionTok{factor}\NormalTok{(temperature),}
      \AttributeTok{Y =} \FunctionTok{factor}\NormalTok{(Y))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.factor}\NormalTok{(mine}\SpecialCharTok{$}\NormalTok{Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{splitting-the-dataset}{%
\section{Splitting the Dataset}\label{splitting-the-dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ames\_split  }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(mine, }
                             \AttributeTok{strata =}\NormalTok{ Y,}
                             \AttributeTok{breaks =} \DecValTok{4}\NormalTok{)}
\NormalTok{ames\_train  }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(ames\_split)}
\NormalTok{ames\_test   }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(ames\_split)}
\end{Highlighting}
\end{Shaded}

\hypertarget{creating-the-recipe}{%
\section{Creating the Recipe}\label{creating-the-recipe}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_rec }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ ames\_train) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{step\_dummy}\NormalTok{(}\FunctionTok{all\_nominal\_predictors}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Let's check if the recipe works. The data below is what it looks like
after processing it with recipe. This is the way our models will read it

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_rec }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{prep}\NormalTok{(}\AttributeTok{training =}\NormalTok{ ames\_train, }\AttributeTok{retain =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{juice}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 93
##   has_children toCoupon_GEQ15min toCoupon_GEQ25min direction_same direction_opp
##          <int>             <int>             <int>          <int>         <int>
## 1            1                 1                 0              0             1
## 2            1                 1                 0              0             1
## 3            1                 0                 0              0             1
## 4            1                 0                 0              0             1
## 5            0                 0                 0              0             1
## 6            0                 1                 0              0             1
## # ... with 88 more variables: Y <fct>, destination_No.Urgent.Place <dbl>,
## #   destination_Work <dbl>, passanger_Friend.s. <dbl>, passanger_Kid.s. <dbl>,
## #   passanger_Partner <dbl>, weather_Snowy <dbl>, weather_Sunny <dbl>,
## #   temperature_X55 <dbl>, temperature_X80 <dbl>, time_X10PM <dbl>,
## #   time_X2PM <dbl>, time_X6PM <dbl>, time_X7AM <dbl>,
## #   coupon_Carry.out...Take.away <dbl>, coupon_Coffee.House <dbl>,
## #   coupon_Restaurant..20. <dbl>, coupon_Restaurant.20.50. <dbl>,
## #   expiration_X2h <dbl>, gender_Male <dbl>, age_X26 <dbl>, age_X31 <dbl>,
## #   age_X36 <dbl>, age_X41 <dbl>, age_X46 <dbl>, age_X50plus <dbl>,
## #   age_below21 <dbl>, maritalStatus_Married.partner <dbl>,
## #   maritalStatus_Single <dbl>, maritalStatus_Unmarried.partner <dbl>,
## #   maritalStatus_Widowed <dbl>, education_Bachelors.degree <dbl>,
## #   education_Graduate.degree..Masters.or.Doctorate. <dbl>,
## #   education_High.School.Graduate <dbl>,
## #   education_Some.college...no.degree <dbl>, education_Some.High.School <dbl>,
## #   occupation_Arts.Design.Entertainment.Sports...Media <dbl>,
## #   occupation_Building...Grounds.Cleaning...Maintenance <dbl>,
## #   occupation_Business...Financial <dbl>,
## #   occupation_Community...Social.Services <dbl>,
## #   occupation_Computer...Mathematical <dbl>,
## #   occupation_Construction...Extraction <dbl>,
## #   occupation_Education.Training.Library <dbl>,
## #   occupation_Farming.Fishing...Forestry <dbl>,
## #   occupation_Food.Preparation...Serving.Related <dbl>,
## #   occupation_Healthcare.Practitioners...Technical <dbl>,
## #   occupation_Healthcare.Support <dbl>,
## #   occupation_Installation.Maintenance...Repair <dbl>, occupation_Legal <dbl>,
## #   occupation_Life.Physical.Social.Science <dbl>, occupation_Management <dbl>,
## #   occupation_Office...Administrative.Support <dbl>,
## #   occupation_Personal.Care...Service <dbl>,
## #   occupation_Production.Occupations <dbl>,
## #   occupation_Protective.Service <dbl>, occupation_Retired <dbl>,
## #   occupation_Sales...Related <dbl>, occupation_Student <dbl>,
## #   occupation_Transportation...Material.Moving <dbl>,
## #   occupation_Unemployed <dbl>, income_X.12500. <dbl>, income_X.25000. <dbl>,
## #   income_X.37500. <dbl>, income_X.50000. <dbl>, income_X.62500. <dbl>,
## #   income_X.75000. <dbl>, income_X.87500. <dbl>,
## #   income_Less.than..12500 <dbl>, Bar_X1.3 <dbl>, Bar_X4.8 <dbl>,
## #   Bar_gt8 <dbl>, Bar_less1 <dbl>, Bar_never <dbl>, CoffeeHouse_X1.3 <dbl>,
## #   CoffeeHouse_X4.8 <dbl>, CoffeeHouse_gt8 <dbl>, CoffeeHouse_less1 <dbl>,
## #   CoffeeHouse_never <dbl>, RestaurantLessThan20_X1.3 <dbl>,
## #   RestaurantLessThan20_X4.8 <dbl>, RestaurantLessThan20_gt8 <dbl>,
## #   RestaurantLessThan20_less1 <dbl>, RestaurantLessThan20_never <dbl>,
## #   Restaurant20To50_X1.3 <dbl>, Restaurant20To50_X4.8 <dbl>,
## #   Restaurant20To50_gt8 <dbl>, Restaurant20To50_less1 <dbl>,
## #   Restaurant20To50_never <dbl>
\end{verbatim}

\hypertarget{specifying-our-models}{%
\section{Specifying Our Models}\label{specifying-our-models}}

We shall be working with four models; Logistic Regression, MARS, Random
Forest (named treebag), and XGBOOST

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_spec }\OtherTok{\textless{}{-}} \FunctionTok{logistic\_reg}\NormalTok{(}\AttributeTok{penalty =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\AttributeTok{engine =} \StringTok{"glmnet"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\NormalTok{mars\_spec }\OtherTok{\textless{}{-}} \FunctionTok{mars}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"earth"}\NormalTok{)}

\NormalTok{treebag\_spec }\OtherTok{\textless{}{-}} \FunctionTok{rand\_forest}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"ranger"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}

\NormalTok{xgboost\_spec }\OtherTok{\textless{}{-}} \FunctionTok{boost\_tree}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"xgboost"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{adding-our-models-and-recipe-into-various-workflows}{%
\section{Adding Our Models and Recipe Into Various
Workflows}\label{adding-our-models-and-recipe-into-various-workflows}}

A workflow is created for each model, but with the same recipe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wf\_log }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_recipe}\NormalTok{(train\_rec) }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_model}\NormalTok{(log\_spec)}

\NormalTok{wf\_mars }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_recipe}\NormalTok{(train\_rec) }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_model}\NormalTok{(mars\_spec)}

\NormalTok{wf\_treebag }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_recipe}\NormalTok{(train\_rec) }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_model}\NormalTok{(treebag\_spec)}

\NormalTok{wf\_xgboost }\OtherTok{\textless{}{-}} \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_recipe}\NormalTok{(train\_rec) }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{add\_model}\NormalTok{(xgboost\_spec)}
\end{Highlighting}
\end{Shaded}

\hypertarget{building-our-logistic-model}{%
\section{Building Our Logistic
Model}\label{building-our-logistic-model}}

First of all, let us start with fitting the train data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_fit\_log }\OtherTok{\textless{}{-}} 
\NormalTok{  wf\_log }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{fit}\NormalTok{(}\AttributeTok{data =}\NormalTok{ ames\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

Now we move to predicting the test data. Note that the data was also
processed with the recipe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_log }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(train\_fit\_log, ames\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

What is the accuracy of our model prediction?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{LOG\_Accuracy }\OtherTok{\textless{}{-}}\NormalTok{ pred\_log }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Y, .pred\_class)}

\NormalTok{LOG\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5684111
\end{verbatim}

With an accuracy of 56.8\%, there s room for improvement. Let's plot a
confusion matrix for the model for better visualization.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(pred\_log, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Logistic"}\NormalTok{,}
       \AttributeTok{subtitle =}\NormalTok{ LOG\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]])}

\NormalTok{p1}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-14-1.pdf}


\hypertarget{building-our-mars-model}{%
\section{Building Our MARS Model}\label{building-our-mars-model}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_fit\_mars }\OtherTok{\textless{}{-}} 
\NormalTok{  wf\_mars }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{fit}\NormalTok{(}\AttributeTok{data =}\NormalTok{ ames\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_mars }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(train\_fit\_mars, ames\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MARS\_Accuracy }\OtherTok{\textless{}{-}}\NormalTok{ pred\_mars }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Y, .pred\_class)}

\NormalTok{MARS\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6815889
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(pred\_mars, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"MARS"}\NormalTok{,}
       \AttributeTok{subtitle =}\NormalTok{ MARS\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]])}

\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-15-1.pdf}

\hypertarget{building-our-random-forest-model}{%
\section{Building Our Random Forest
Model}\label{building-our-random-forest-model}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_fit\_treebag }\OtherTok{\textless{}{-}} 
\NormalTok{  wf\_treebag }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{fit}\NormalTok{(}\AttributeTok{data =}\NormalTok{ ames\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_treebag }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(train\_fit\_treebag, ames\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TREEBAG\_Accuracy }\OtherTok{\textless{}{-}}\NormalTok{ pred\_treebag }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Y, .pred\_class)}

\NormalTok{TREEBAG\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7566204
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p3 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(pred\_treebag, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Random Frest"}\NormalTok{,}
       \AttributeTok{subtitle =}\NormalTok{ TREEBAG\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]])}

\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-16-1.pdf}

\hypertarget{building-our-xgboost-model}{%
\section{Building Our XGBOOST Model}\label{building-our-xgboost-model}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_fit\_xgboost }\OtherTok{\textless{}{-}} 
\NormalTok{  wf\_xgboost }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{fit}\NormalTok{(}\AttributeTok{data =}\NormalTok{ ames\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{verbatim}
## [00:56:49] WARNING: amalgamation/../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_xgboost }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(train\_fit\_xgboost, ames\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XGBOOST\_Accuracy }\OtherTok{\textless{}{-}}\NormalTok{ pred\_xgboost }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{accuracy}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Y, .pred\_class)}

\NormalTok{XGBOOST\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7459016
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(pred\_xgboost, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"XGBOOST"}\NormalTok{,}
       \AttributeTok{subtitle =}\NormalTok{ XGBOOST\_Accuracy[[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]])}

\NormalTok{p4}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-17-1.pdf}

\hypertarget{confusion-matrix-for-every-model}{%
\section{Confusion Matrix for Every
Model}\label{confusion-matrix-for-every-model}}

We can see that the Random Forest model is best while the MARS is the
worst.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggpubr}\SpecialCharTok{::}\FunctionTok{ggarrange}\NormalTok{(p1,p2,p3,p4,}
                   \AttributeTok{ncol =} \DecValTok{2}\NormalTok{,}
                   \AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-18-1.pdf}

\hypertarget{ensembling-our-models}{%
\section{Ensembling Our Models}\label{ensembling-our-models}}

Let us start by creating our cross validation folds

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ctrl\_grid }\OtherTok{\textless{}{-}}\NormalTok{ stacks}\SpecialCharTok{::}\FunctionTok{control\_stack\_grid}\NormalTok{()}
\NormalTok{ctrl\_res }\OtherTok{\textless{}{-}}\NormalTok{ stacks}\SpecialCharTok{::}\FunctionTok{control\_stack\_resamples}\NormalTok{()}

\NormalTok{folds }\OtherTok{\textless{}{-}}\NormalTok{ rsample}\SpecialCharTok{::}\FunctionTok{vfold\_cv}\NormalTok{(ames\_train, }\AttributeTok{v =} \DecValTok{5}\NormalTok{)}

\NormalTok{metric }\OtherTok{\textless{}{-}} \FunctionTok{metric\_set}\NormalTok{(accuracy, roc\_auc)}
\end{Highlighting}
\end{Shaded}

\hypertarget{preparing-the-mars-model-for-ensembling}{%
\section{Preparing the MARS Model for
Ensembling}\label{preparing-the-mars-model-for-ensembling}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mars\_res }\OtherTok{\textless{}{-}} 
  \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{    wf\_mars, }\CommentTok{\#workflow}
    \AttributeTok{resamples =}\NormalTok{ folds, }\CommentTok{\#cvfold}
    \AttributeTok{metrics =}\NormalTok{ metric,}
    \AttributeTok{control =}\NormalTok{ ctrl\_res}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\hypertarget{preparing-the-random-forest-model-for-ensembling}{%
\section{Preparing the Random Forest Model for
Ensembling}\label{preparing-the-random-forest-model-for-ensembling}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{treebag\_res }\OtherTok{\textless{}{-}} 
  \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{    wf\_treebag, }\CommentTok{\#workflow}
    \AttributeTok{resamples =}\NormalTok{ folds, }\CommentTok{\#cvfold}
    \AttributeTok{metrics =}\NormalTok{ metric,}
    \AttributeTok{control =}\NormalTok{ ctrl\_res}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\hypertarget{preparing-the-xgboost-model-for-ensembling}{%
\section{Preparing the XGBOOST Model for
Ensembling}\label{preparing-the-xgboost-model-for-ensembling}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xgboost\_res }\OtherTok{\textless{}{-}} 
  \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{    wf\_xgboost, }\CommentTok{\#workflow}
    \AttributeTok{resamples =}\NormalTok{ folds, }\CommentTok{\#cvfold}
    \AttributeTok{metrics =}\NormalTok{ metric,}
    \AttributeTok{control =}\NormalTok{ ctrl\_res}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\hypertarget{preparing-the-logistic-model-for-ensembling}{%
\section{Preparing the Logistic Model for
Ensembling}\label{preparing-the-logistic-model-for-ensembling}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_res }\OtherTok{\textless{}{-}} 
  \FunctionTok{fit\_resamples}\NormalTok{(}
\NormalTok{    wf\_log, }\CommentTok{\#workflow}
    \AttributeTok{resamples =}\NormalTok{ folds, }\CommentTok{\#cvfold}
    \AttributeTok{metrics =}\NormalTok{ metric,}
    \AttributeTok{control =}\NormalTok{ ctrl\_res}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\hypertarget{adding-every-model-to-our-stack}{%
\section{Adding Every Model to Our
Stack}\label{adding-every-model-to-our-stack}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stacks)}
\NormalTok{model\_data\_st }\OtherTok{\textless{}{-}}  \FunctionTok{stacks}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_candidates}\NormalTok{(log\_res) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_candidates}\NormalTok{(treebag\_res) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_candidates}\NormalTok{(xgboost\_res) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_candidates}\NormalTok{(mars\_res)}

\FunctionTok{head}\NormalTok{(model\_data\_st)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A data stack with 4 model definitions and 4 candidate members:
## #   log_res: 1 model configuration
## #   treebag_res: 1 model configuration
## #   xgboost_res: 1 model configuration
## #   mars_res: 1 model configuration
## # Outcome: Y (factor)
\end{verbatim}

There are several class probabilities. To know the combined model
prediction, we will use the blend\_predictions() function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fitted\_model\_st }\OtherTok{\textless{}{-}}
\NormalTok{  model\_data\_st }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{blend\_predictions}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Let us expore our ensambled model to know how the members are
performing.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_bw}\NormalTok{())}
\FunctionTok{autoplot}\NormalTok{(fitted\_model\_st)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-26-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(fitted\_model\_st, }\AttributeTok{type =} \StringTok{"members"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-27-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(fitted\_model\_st, }\AttributeTok{type =} \StringTok{"weights"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-28-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fitted\_model\_st}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- A stacked ensemble model -------------------------------------
\end{verbatim}

\begin{verbatim}
## 
## Out of 4 possible candidate members, the ensemble retained 2.
## Penalty: 0.01.
## Mixture: 1.
\end{verbatim}

\begin{verbatim}
## 
## The 2 highest weighted member classes are:
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 3
##   member                  type        weight
##   <chr>                   <chr>        <dbl>
## 1 .pred_1_treebag_res_1_1 rand_forest  6.41 
## 2 .pred_1_xgboost_res_1_1 boost_tree   0.485
\end{verbatim}

\begin{verbatim}
## 
## Members have not yet been fitted with `fit_members()`.
\end{verbatim}

The final model retained just three of our models; MARS, Random Forest,
and XGBOOST. Let us combine these models to predict our test data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fitted\_model\_st }\OtherTok{\textless{}{-}}
\NormalTok{  fitted\_model\_st }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fit\_members}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{verbatim}
## [01:01:35] WARNING: amalgamation/../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_predict\_data }\OtherTok{\textless{}{-}} 
\NormalTok{  ames\_test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fitted\_model\_st, .))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

Prediting the test data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{member\_preds }\OtherTok{\textless{}{-}} 
\NormalTok{  test\_predict\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(Y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fitted\_model\_st, ames\_test, }\AttributeTok{members =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
## New names:
## * income_X.12500....24999 -> income_X.12500.
## * income_X.25000....37499 -> income_X.25000.
## * income_X.37500....49999 -> income_X.37500.
## * income_X.50000....62499 -> income_X.50000.
## * income_X.62500....74999 -> income_X.62500.
## * ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(member\_preds)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Y .pred_class .pred_class_treebag_res_1_1 .pred_class_xgboost_res_1_1
## 1 0           0                           0                           0
## 2 1           1                           1                           1
## 3 0           0                           0                           0
## 4 0           0                           0                           0
## 5 1           0                           0                           0
## 6 0           0                           0                           1
\end{verbatim}

Let us compare the accuracy of the combined model with that of the other
member models

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map\_dfr}\NormalTok{(member\_preds, accuracy, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{data =}\NormalTok{ member\_preds) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{member =} \FunctionTok{colnames}\NormalTok{(member\_preds))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   .metric  .estimator .estimate member                     
##   <chr>    <chr>          <dbl> <chr>                      
## 1 accuracy binary         1     Y                          
## 2 accuracy binary         0.758 .pred_class                
## 3 accuracy binary         0.757 .pred_class_treebag_res_1_1
## 4 accuracy binary         0.746 .pred_class_xgboost_res_1_1
\end{verbatim}

After every model learned from each other, the model with the highest
accuracy is MARS (74.59\%) while the combined model came second
(74.55\%). XGBOOST came last (73.865\%).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(member\_preds, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Ensembled"}\NormalTok{)}

\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(member\_preds, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class\_treebag\_res\_1\_1) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Random Forest"}\NormalTok{)}

\NormalTok{p3 }\OtherTok{\textless{}{-}} \FunctionTok{conf\_mat}\NormalTok{(member\_preds, }\AttributeTok{truth =}\NormalTok{ Y, }\AttributeTok{estimate =}\NormalTok{ .pred\_class\_xgboost\_res\_1\_1) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{autoplot}\NormalTok{(}\AttributeTok{type =} \StringTok{"heatmap"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"XGBOOST"}\NormalTok{)}

\NormalTok{ggpubr}\SpecialCharTok{::}\FunctionTok{ggarrange}\NormalTok{(p1,p2,p3,}
          \AttributeTok{ncol =} \DecValTok{2}\NormalTok{,}
          \AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ensembling-different-classification-models_files/figure-latex/unnamed-chunk-34-1.pdf}

\hypertarget{thanks-for-reading}{%
\section{Thanks for Reading}\label{thanks-for-reading}}

\end{document}
