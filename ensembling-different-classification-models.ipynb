{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Trying Out and Ensembling Different Classification Models \n",
                "\n",
                "**This is the second complete notebook that I am creating. [Here's a link to the first](https://github.com/elijahrona/Elijah-Rona-ML-Journey/blob/master/do-you-have-malaria-or-covid-19.ipynb) where I worked with Covid-19, Malaria, and Negative patients.**\n",
                "\n",
                "**The purpose of this notebook is to improve my Recipes(), Workflow(), and Ensembling (Stacks()) skills.**\n",
                "\n",
                "# Importing Libraries\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(tidyverse)\n",
                "library(tidymodels)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mine <- read.csv(\"C:/Users/Octopus/Desktop/in-vehicle-coupon-recommendation.csv\", stringsAsFactors=TRUE)\n",
                "head(mine)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's have a glimpse of what our dataset looks like.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skimmed <- skimr::skim(mine)\n",
                "skimmed <- skimmed[, c(1:5, 9:11, 13, 15)]\n",
                "skimmed\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The response variable, Y appears to be numeric. It should be a factor, so we should convert it with factor(). Also, it seems that the temperature column has only three numbers, so we should also treat it as a factor.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mine <- mine %>%\n",
                "mutate(temperature = factor(temperature),\n",
                "      Y = factor(Y))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "is.factor(mine$Y)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Splitting the Dataset\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ames_split  <- initial_split(mine, \n",
                "                             strata = Y,\n",
                "                             breaks = 4)\n",
                "ames_train  <- training(ames_split)\n",
                "ames_test   <- testing(ames_split)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creating the Recipe\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_rec <- recipe(Y ~ ., data = ames_train) %>%\n",
                "step_dummy(all_nominal_predictors())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check if the recipe works. The data below is what it looks like after processing it with recipe. This is the way our models will read it\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_rec %>% \n",
                "prep(training = ames_train, retain = TRUE) %>%\n",
                "juice() %>%\n",
                "head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Specifying Our Models\n",
                "\n",
                "We shall be working with four models; Logistic Regression, MARS, Random Forest (named treebag), and XGBOOST\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_spec <- logistic_reg(penalty = 10) %>%\n",
                "  set_engine(engine = \"glm\") %>%\n",
                "  set_mode(\"classification\")\n",
                "\n",
                "mars_spec <- mars() %>%\n",
                "  set_mode(\"classification\") %>% \n",
                "  set_engine(\"earth\")\n",
                "\n",
                "treebag_spec <- rand_forest() %>%\n",
                "  set_engine(\"ranger\") %>% \n",
                "  set_mode(\"classification\")\n",
                "\n",
                "xgboost_spec <- boost_tree() %>% \n",
                "  set_mode(\"classification\") %>% \n",
                "  set_engine(\"xgboost\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adding Our Models and Recipe Into Various Workflows\n",
                "\n",
                "A workflow is created for each model, but with the same recipe\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wf_log <- workflow() %>% \n",
                "add_recipe(train_rec) %>% \n",
                "add_model(log_spec)\n",
                "\n",
                "wf_mars <- workflow() %>% \n",
                "add_recipe(train_rec) %>% \n",
                "add_model(mars_spec)\n",
                "\n",
                "wf_treebag <- workflow() %>% \n",
                "add_recipe(train_rec) %>% \n",
                "add_model(treebag_spec)\n",
                "\n",
                "wf_xgboost <- workflow() %>% \n",
                "add_recipe(train_rec) %>% \n",
                "add_model(xgboost_spec)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building Our Logistic Model\n",
                "\n",
                "First of all, let us start with fitting the train data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_fit_log <- \n",
                "  wf_log %>% \n",
                "  fit(data = ames_train)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we move to predicting the test data. Note that the data was also processed with the recipe\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pred_log <- augment(train_fit_log, ames_test)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What is the accuracy of our model prediction?\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LOG_Accuracy <- pred_log %>% \n",
                "  accuracy(truth = Y, .pred_class)\n",
                "\n",
                "LOG_Accuracy[[1,3]]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "With an accuracy of 56.8%, there s room for improvement. Let's plot a confusion matrix for the model for better visualization.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p1 <- conf_mat(pred_log, truth = Y, estimate = .pred_class) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"Logistic\",\n",
                "       subtitle = LOG_Accuracy[[1,3]])\n",
                "\n",
                "p1\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Logistic model is very poor. It could not detect any 0\n",
                "\n",
                "\n",
                "# Building Our MARS Model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_fit_mars <- \n",
                "  wf_mars %>% \n",
                "  fit(data = ames_train)\n",
                "\n",
                "pred_mars <- augment(train_fit_mars, ames_test)\n",
                "\n",
                "MARS_Accuracy <- pred_mars %>% \n",
                "  accuracy(truth = Y, .pred_class)\n",
                "\n",
                "MARS_Accuracy[[1,3]]\n",
                "\n",
                "p2 <- conf_mat(pred_mars, truth = Y, estimate = .pred_class) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"MARS\",\n",
                "       subtitle = MARS_Accuracy[[1,3]])\n",
                "\n",
                "p2\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building Our Random Forest Model\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_fit_treebag <- \n",
                "  wf_treebag %>% \n",
                "  fit(data = ames_train)\n",
                "\n",
                "pred_treebag <- augment(train_fit_treebag, ames_test)\n",
                "\n",
                "TREEBAG_Accuracy <- pred_treebag %>% \n",
                "  accuracy(truth = Y, .pred_class)\n",
                "\n",
                "TREEBAG_Accuracy[[1,3]]\n",
                "\n",
                "p3 <- conf_mat(pred_treebag, truth = Y, estimate = .pred_class) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"Random Frest\",\n",
                "       subtitle = TREEBAG_Accuracy[[1,3]])\n",
                "\n",
                "p3\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building Our XGBOOST Model\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_fit_xgboost <- \n",
                "  wf_xgboost %>% \n",
                "  fit(data = ames_train)\n",
                "\n",
                "pred_xgboost <- augment(train_fit_xgboost, ames_test)\n",
                "\n",
                "XGBOOST_Accuracy <- pred_xgboost %>% \n",
                "  accuracy(truth = Y, .pred_class)\n",
                "\n",
                "XGBOOST_Accuracy[[1,3]]\n",
                "\n",
                "p4 <- conf_mat(pred_xgboost, truth = Y, estimate = .pred_class) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"XGBOOST\",\n",
                "       subtitle = XGBOOST_Accuracy[[1,3]])\n",
                "\n",
                "p4\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Confusion Matrix for Every Model\n",
                "\n",
                "We can see that the Random Forest model is best while the MARS is the worst.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggpubr::ggarrange(p1,p2,p3,p4,\n",
                "                   ncol = 2,\n",
                "                   nrow = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Ensembling Our Models\n",
                "\n",
                "Let us start by creating our cross validation folds\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ctrl_grid <- stacks::control_stack_grid()\n",
                "ctrl_res <- stacks::control_stack_resamples()\n",
                "\n",
                "folds <- rsample::vfold_cv(ames_train, v = 5)\n",
                "\n",
                "metric <- metric_set(accuracy, roc_auc)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparing the MARS Model for Ensembling\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mars_res <- \n",
                "  fit_resamples(\n",
                "    wf_mars, #workflow\n",
                "    resamples = folds, #cvfold\n",
                "    metrics = metric,\n",
                "    control = ctrl_res\n",
                "  )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparing the Random Forest Model for Ensembling\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "treebag_res <- \n",
                "  fit_resamples(\n",
                "    wf_treebag, #workflow\n",
                "    resamples = folds, #cvfold\n",
                "    metrics = metric,\n",
                "    control = ctrl_res\n",
                "  )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparing the XGBOOST Model for Ensembling\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgboost_res <- \n",
                "  fit_resamples(\n",
                "    wf_xgboost, #workflow\n",
                "    resamples = folds, #cvfold\n",
                "    metrics = metric,\n",
                "    control = ctrl_res\n",
                "  )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparing the Logistic Model for Ensembling\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_res <- \n",
                "  fit_resamples(\n",
                "    wf_log, #workflow\n",
                "    resamples = folds, #cvfold\n",
                "    metrics = metric,\n",
                "    control = ctrl_res\n",
                "  )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adding Every Model to Our Stack\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(stacks)\n",
                "model_data_st <-  stacks() %>%\n",
                "  add_candidates(log_res) %>%\n",
                "  add_candidates(treebag_res) %>%\n",
                "  add_candidates(xgboost_res) %>%\n",
                "  add_candidates(mars_res)\n",
                "\n",
                "head(model_data_st)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are several class probabilities. To know the combined model prediction, we will use the blend_predictions() function.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fitted_model_st <-\n",
                "  model_data_st %>%\n",
                "  blend_predictions()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us expore our ensambled model to know how the members are performing.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "theme_set(theme_bw())\n",
                "autoplot(fitted_model_st)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "autoplot(fitted_model_st, type = \"members\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "autoplot(fitted_model_st, type = \"weights\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fitted_model_st\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The final model retained just two of our models; Random Forest and XGBOOST. Let us combine these models to predict our test data\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fitted_model_st <-\n",
                "  fitted_model_st %>%\n",
                "  fit_members()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_predict_data <- \n",
                "  ames_test %>%\n",
                "  bind_cols(predict(fitted_model_st, .))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Prediting the test data\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "member_preds <- \n",
                "  test_predict_data %>%\n",
                "  select(Y) %>%\n",
                "  bind_cols(predict(fitted_model_st, ames_test, members = TRUE))\n",
                "\n",
                "head(member_preds)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us compare the accuracy of the combined model with that of the other member models\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "map_dfr(member_preds, accuracy, truth = Y, data = member_preds) %>%\n",
                "  mutate(member = colnames(member_preds))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After every model learned from each other, the model with the highest accuracy is Random Forest (74.55%) while the combined model came second (74.14%). XGBOOST came last (72.06%).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p1 <- conf_mat(member_preds, truth = Y, estimate = .pred_class) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"Ensembled\")\n",
                "\n",
                "p2 <- conf_mat(member_preds, truth = Y, estimate = .pred_class_treebag_res_1_1) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"Random Forest\")\n",
                "\n",
                "p3 <- conf_mat(member_preds, truth = Y, estimate = .pred_class_xgboost_res_1_1) %>% \n",
                "  autoplot(type = \"heatmap\") +\n",
                "  labs(title = \"XGBOOST\")\n",
                "\n",
                "ggpubr::ggarrange(p1,p2,p3,\n",
                "          ncol = 2,\n",
                "          nrow = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Thanks for Reading\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
